[
  {
    "objectID": "posts/welcome/index.html",
    "href": "posts/welcome/index.html",
    "title": "Welcome To My Blog",
    "section": "",
    "text": "This is the first post in a Quarto blog. Welcome!\n\nSince this post doesn’t specify an explicit image, the first image in the post will be used in the listing page of posts."
  },
  {
    "objectID": "posts/post-with-code/index.html",
    "href": "posts/post-with-code/index.html",
    "title": "Post With Code",
    "section": "",
    "text": "This is a post with executable code."
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "About this blog"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "dat303-blog",
    "section": "",
    "text": "Post With Code\n\n\n\n\n\n\nnews\n\n\ncode\n\n\nanalysis\n\n\n\n\n\n\n\n\n\nDec 4, 2024\n\n\nHarlow Malloc\n\n\n\n\n\n\n\n\n\n\n\n\nWelcome To My Blog\n\n\n\n\n\n\nnews\n\n\n\n\n\n\n\n\n\nDec 1, 2024\n\n\nTristan O’Malley\n\n\n\n\n\n\n\n\n\n\n\n\nThe Age of Misinformation. A Data Scientist’s Role.\n\n\n\n\n\n\nPython\n\n\n\nAn investigation into online misinformation and how data science is involved.\n\n\n\n\n\nOct 25, 2024\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "posts/post3-titanic/blog3.html",
    "href": "posts/post3-titanic/blog3.html",
    "title": "The Age of Misinformation. A Data Scientist’s Role.",
    "section": "",
    "text": "The Age of Misinformation: A Data Scientist’s Role\nNumbers have an inherit power to them. They bring a sense power and credibility to the arguement, whether it is genuine or not. Be in an advertisement, news article, or post on social media, the inclusion of statistics makes us more inclined to believe the information at face value. This perception stems from the beleif that “the facts” are objective and immune to manipulation.\nThe reality is that numbers are so easily manipulated. They can be selective to show exactly what a company wants, misrepresented in visuals to seem more or less extreme, or be flat out changed to shape the result. Context, methodology, and interpretation are purposefully hidden or ignored for the sake of convincing consumers.\nIn this post I’ll be exploring and demonstrating how simple it is to manipulate data into fitting my narrative. Hopefully this will make people approach data and statistics in media with a critical eye.\nFor this example I’ll be working on a titanic dataset. This is a labeled dataset meaning we know the correct answers for our predictor variable “Surived”. In addition, because the dataset is historical, we know the data to be unbiased. This specific dataset does not include all the people on the titanic, but it is a random sample of the full data. To start I’m importing my libraries, doing simple exploration, and cleaning where needed.\n\n# import our libraries\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n\n# check out our dataset\ndf = pd.read_csv(\"titanic.csv\")\nprint(df.shape)\ndf.head(5)\n\n(891, 5)\n\n\n\n\n\n\n\n\n\nSurvived\nPclass\nGender\nAge\nFare\n\n\n\n\n0\n0\n3\nmale\n22.0\n7.2500\n\n\n1\n1\n1\nfemale\n38.0\n71.2833\n\n\n2\n1\n3\nfemale\n26.0\n7.9250\n\n\n3\n1\n1\nfemale\n35.0\n53.1000\n\n\n4\n0\n3\nmale\n35.0\n8.0500\n\n\n\n\n\n\n\n\nprint(f\"Missing values per column:\\n{df.isna().sum()}\")\nprint(f\"Column dtypes:\\n{df.dtypes}\")\n\nMissing values per column:\nSurvived    0\nPclass      0\nGender      0\nAge         0\nFare        0\ndtype: int64\nColumn dtypes:\nSurvived      int64\nPclass        int64\nGender       object\nAge         float64\nFare        float64\ndtype: object\n\n\nLuckily there are no missing values we have to fix. In this next step all I’m doing is changing the columns to be useable in our models later on. 0 will represent Male passengers and 0 1 will represent female passengers.\n\n# including this next line to avoid errors from future version\npd.set_option('future.no_silent_downcasting', True)\n\n# changing column \"Gender\" to boolean values. \ndf[\"Gender\"] = df[\"Gender\"].replace({\"male\": 0, \"female\": 1})\nprint(df[\"Gender\"].value_counts())\n\nGender\n0    577\n1    314\nName: count, dtype: int64\n\n\nFor the last step in cleaning, we’ll be checking the “Fare” column for any outliers because that could have a huge affect on our model.\n\n# we'll be using a box and whisker plot for outlier detection\nplt.figure(figsize=(8, 6))\nplt.boxplot(df[\"Fare\"].dropna(), patch_artist=True, boxprops=dict(facecolor=\"blue\"))\nplt.title(\"Fare Outliers\")\nplt.xlabel(\"Fare\")\nplt.grid(axis='x')\n\nplt.show()\n\n\n\n\n\n\n\n\nUnfortunately, there are many outliers on the high end for fares. For this dataset, it would not be appropriate to remove or replace any of our outliers because we could be losnig valueable information about what influences the predictor variable “Survived”. However, we still need to perform outlier detection to understand the impact it will have on our model later. Knowing we have so many high end outliers in our data could provide insight when we evaluate later on\nNow that our dataset is ready, we’re going to make a simple train/test split to use in our models. Our predictor variable will be “Survived”, where 0 represents a passenger did not live and 1 represents a survivor. I’m using a decision tree that is limited to 3 splits for the sake of a simple visualization.\n\nx = df.drop(columns=[\"Survived\"]) # drop y variable, keep the rest\ny = df[\"Survived\"]\n\n# train/test split. 80 train, 20 test.\nxtrain, xtest, ytrain, ytest = train_test_split(x, y, test_size= 0.2, random_state=1)\nprint(f\"xtrain shape: {xtrain.shape}\")\nprint(f\"ytrain shape: {ytrain.shape}\")\nprint(f\"xtest shape: {xtest.shape}\")\nprint(f\"ytest shape: {ytest.shape}\")\n\n# creating and fitting our model\nmdl1 = LogisticRegression(random_state=1)\nmdl1.fit(xtrain, ytrain)\n\n# create predictions\nypred = mdl1.predict(xtest)\n\nxtrain shape: (712, 4)\nytrain shape: (712,)\nxtest shape: (179, 4)\nytest shape: (179,)\n\n\nNow that our model has ran we’re going to look at it’s performance. Please note that LogisticRegression is being used here for the sake of simplicity for our example. LogisticRegression assumes the variables are independent of each other, meaning one value has no affect on the others. For our dataset, the x variables are independent so we don’t have to worry about that. It is also sensitive to outliers. We screened our float value, “Fare” for outliers earlier and found many. However, as discussed earlier, it is not appropriate to remove these so we will be evaluating with that in mind.\nWe’ll be looking at the overall accuracy score and a confusion matrix to evaluate. The accuracy score is straightforward, its the number of correct predictions over the total points predicted.\n\naccuracy = accuracy_score(ytest, ypred)\nprint(f\"Accuracy of Model 1: {accuracy:.5f}\")\n\nAccuracy of Model 1: 0.79888\n\n\nAlthough far from perfect, a (rounded) accuracy score of 80% is a fairly good performance for our LogisticRegression model. In other words, our model correctly predicted 143 points of our 179 included in ytest. I’ll discuss this more later, but note that even our labeled, unedited data fails to predict points perfectly.\nNext we’ll be looking at a confusion matrix. This provides a simple visual to see how our model is predicting points. This will provide insight into what types of points the model is best at predicting and where it struggles.\n\nconf_matrix = confusion_matrix(ytest, ypred)\nprint(conf_matrix)\n\nissues: - despite using ‘pure’ data, where we know the answers, the predictor model is not 100% accurate because errors are going to happen no matter what - this alone is enough to be skeptical of peoples numbers - but it can get so much worse too\nintroduce falsifying data - now say the titanic happened today, and we work for a news outlet that wants to push the idea that the famous line ‘women and children’ was true, regardless of class/ticket - the real data did not look good for this claim, or we want it to look even better - so i’ll edit the data to show all women survived the crash\n\n# edit the column survived on a new df\n\nnow we’ll run the same decision tree, same parameters, on our edited dataset\n\n# run model\n# print same metrics\n\n\nchanges the results completely\npushes our narrative\ntook 2 seconds to change the entire story\nfor this demonstration we know its not true, and its historical data so changing results doesn’t really have an impact\nbut say we instead worked for an insurance company, and we were told to decrease the amount paid out on claims. or we worked in sales and our boss asked us to make the sales figures look better.\nthen it actually impacts people. claims who really need it are rejected and the boss looks good on paper while the business is actually failing\nit becomes the ethical responsibility of data scientists to uphold truthful data and results\nneed to ensure the data source is good\n\nreference the LA police deployment issue\n\n\n\n# breifly show code here if you can find the dataset/link to an article about it to break up the text\n\n\nit is unethical to change the data for your own gain\ncauses issues in real life, rapid spread of misinformation\nnot only an issue with numbers, but journalism have had this issue forever. numbers just make it more believeable\nalso the NEW responsibility of people today, especially online, to be wary of the numbers/data because its not always true\nneed to watch for the source of the data, the scale in how its displayed, what its being compared to, etc\nall too easy to make stuff up, to safely navigate the internet people need to understand this\ndata scientist job to not make it any harder on people"
  }
]